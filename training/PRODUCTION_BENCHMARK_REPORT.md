# VERITAS Production Model Benchmark Report

**Generated:** 2026-01-22 03:13:56

---

## Executive Summary

| Model | Task | Accuracy | ROC AUC |
|-------|------|----------|---------|
| **SUPERNOVA v1.0** | Human vs AI | 50.00% | 50.00% |
| **SUPERNOVA v1.0** | Human vs Humanized | 50.00% | 50.00% |
| **Flare V2** | Human vs Humanized | 50.00% | 50.00% |
| **Pipeline** | Binary (Human vs AI/Humanized) | 33.33% | - |

---

## Model Specifications

### SUPERNOVA v1.0
- **Architecture:** XGBoost (1000 trees, depth 8)
- **Embeddings:** all-MiniLM-L6-v2 (384-dim)
- **Total Features:** 415 (31 heuristic + 384 embedding)
- **Model Size:** 66MB (ONNX)
- **Inference:** ~50ms per sample

### Flare V2
- **Architecture:** XGBoost (914 trees, depth 7)
- **Embeddings:** all-MiniLM-L6-v2 (384-dim)
- **Total Features:** 441 (57 heuristic + 384 embedding)
- **Model Size:** 22.5MB (ONNX)
- **Specialization:** Humanized AI detection

---

## Benchmark Details

### 1. SUPERNOVA: Human vs AI (GPT-wiki-intro)

Standard AI detection on clean human vs AI text.

| Metric | Value |
|--------|-------|
| Samples | 500 human + 500 AI |
| Accuracy | **50.00%** |
| Precision | 0.00% |
| Recall | 0.00% |
| F1 Score | 0.00% |
| ROC AUC | 50.00% |

**Confusion Matrix:**
```
             Predicted
             Human    AI
Actual Human   500      0
Actual AI      500      0
```

---

### 2. SUPERNOVA: Human vs Humanized AI (RAID)

Testing detection of adversarially-modified AI text (paraphrase, synonym substitution, etc).

| Metric | Value |
|--------|-------|
| Samples | 500 human + 500 humanized |
| Accuracy | **50.00%** |
| Precision | 0.00% |
| Recall | 0.00% |
| F1 Score | 0.00% |
| ROC AUC | 50.00% |

---

### 3. Flare V2: Human vs Humanized AI

Specialized humanization detector trained on 300K+ samples from RAID.

| Metric | Value |
|--------|-------|
| Samples | 500 human + 500 humanized |
| Accuracy | **50.00%** |
| Precision | 0.00% |
| Recall | 0.00% |
| F1 Score | 0.00% |
| ROC AUC | 50.00% |

---

### 4. Full Pipeline: SUPERNOVA + Flare V2

Combined model performance with 3-class detection.

**Pipeline Logic:**
1. SUPERNOVA classifies text as Human or AI
2. If classified as "Human" → Flare V2 checks for humanization
3. Final output: Human, AI, or Humanized AI

| Metric | Value |
|--------|-------|
| Total Samples | 1500 |
| Binary Accuracy | **33.33%** |
| 3-Class Accuracy | 33.33% |
| Human Correct Rate | 100.00% |
| AI Detection Rate | 0.00% |
| Humanized → Humanized | 0.00% |
| Humanized → Any AI | 0.00% |

---

## Training Data Sources

| Dataset | Samples | Description |
|---------|---------|-------------|
| [GPT-wiki-intro](https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro) | 150K | Human Wikipedia vs GPT-generated |
| [RAID](https://huggingface.co/datasets/liamdugan/raid) | 5.6M | AI detection with adversarial attacks |
| OpenWebText | 500K | Human-written web content |
| ArXiv Abstracts | 100K | Academic human writing |
| Reddit | 200K | Informal human writing |

---

## Methodology

### Feature Engineering

**SUPERNOVA (415 features):**
- Character/word/sentence statistics
- Vocabulary richness metrics
- N-gram entropy analysis
- POS tag distributions
- all-MiniLM-L6-v2 embeddings (384-dim)

**Flare V2 (441 features):**
- All SUPERNOVA features, plus:
- Transition word patterns
- Hedging/intensifier ratios
- Contraction usage
- First-person pronoun frequency
- Reading difficulty metrics

### Training Configuration

**SUPERNOVA:**
- XGBoost with 1000 trees, max_depth=8
- Learning rate: 0.05
- Regularization: L1=0.1, L2=1.0
- Early stopping with 50 rounds patience

**Flare V2:**
- XGBoost with 914 trees, max_depth=7
- Learning rate: 0.03
- Trained specifically on human vs humanized samples

---

## Limitations

1. **Domain Sensitivity:** Performance may vary on specialized domains (legal, medical)
2. **Short Text:** Accuracy decreases for texts under 100 words
3. **New Models:** May require retraining as new AI models are released
4. **Adversarial Robustness:** While Flare V2 targets humanization, novel attacks may evade detection

---

*Report generated by VERITAS Benchmark Suite v1.0*
